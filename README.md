# distributed-torch-horovod-gcp
A small example of using GCP horovod and PyTorch for dist training
